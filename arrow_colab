from google.colab import drive
drive.mount('/content/itsdrive')

import imgaug as ia
from imgaug import augmenters as iaa
import numpy as np
import imageio
from PIL import Image

seq = iaa.Sequential([
    iaa.Affine(translate_percent={"x": (-0.25, 0.25), "y": (-0.4, 0.4)}),
    iaa.Fliplr(0.5),
])

image = Image.open("/content/itsdrive/MyDrive/Aurora/2D vectors/Screenshot from 2023-10-26 20-12-21 (copy).png")
image = image.convert("RGB")

center_x, center_y, relative_width, relative_height = 0.433196, 0.475424, 0.328329, 0.125182

image_width, image_height = image.size
x1 = int((center_x - relative_width / 2) * image_width)
y1 = int((center_y - relative_height / 2) * image_height)
x2 = int((center_x + relative_width / 2) * image_width)
y2 = int((center_y + relative_height / 2) * image_height)

bounding_box = ia.BoundingBox(x1=x1, y1=y1, x2=x2, y2=y2)
bounding_boxes = [bounding_box]

counter = 0
save_directory = "/content/itsdrive/MyDrive/Aurora/Yolov8/data/images/train/"
labels_directory = "/content/itsdrive/MyDrive/Aurora/Yolov8/data/labels/train/"

for _ in range(100):
    image_aug, bounding_boxes_aug = seq(image=np.array(image), bounding_boxes=bounding_boxes)
    bounding_boxes_aug = [bb.clip_out_of_image(np.array(image)) for bb in bounding_boxes_aug]
    image_aug = Image.fromarray(image_aug)

    image_filename = f"{save_directory}augmented_image_{counter}.jpg"
    image_aug.save(image_filename)

    label_filename = f"{labels_directory}augmented_image_{counter}.txt"
    with open(label_filename, 'w') as label_file:
        x1, y1, x2, y2 = bounding_boxes_aug[0].x1, bounding_boxes_aug[0].y1, bounding_boxes_aug[0].x2, bounding_boxes_aug[0].y2
        width = x2 - x1
        height = y2 - y1
        center_x = (x1 + x2) / 2 / image_width
        center_y = (y1 + y2) / 2 / image_height
        label_file.write(f"0 {center_x:.6f} {center_y:.6f} {width / image_width:.6f} {height / image_height:.6f}")

    counter += 1

!pip install ultralytics
from ultralytics import YOLO

model = YOLO("yolov8n.yaml")
results = model.train(data="/content/itsdrive/MyDrive/Aurora/Yolov8/mag.yaml", epochs=100)

import os
from ultralytics import YOLO
import cv2

IMAGES_DIR = '/content/itsdrive/MyDrive/Aurora/ggg'
OUTPUT_DIR = '/content/itsdrive/MyDrive/Aurora/Yolov8/predictions'

image_files = [os.path.join(IMAGES_DIR, filename) for filename in os.listdir(IMAGES_DIR) if filename.endswith(('.jpg', '.png'))]

model_path = os.path.join('.', 'runs', 'detect', 'train', 'weights', 'last.pt')

model = YOLO('runs/detect/train/weights/best.pt')

threshold = 0.3

for image_file in image_files:
    frame = cv2.imread(image_file)
    H, W, _ = frame.shape

    results = model(frame)[0]

    for result in results.boxes.data.tolist():
        x1, y1, x2, y2, score, class_id = result

        if score > threshold:
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)
            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)

    output_file = os.path.join(OUTPUT_DIR, os.path.basename(image_file))
    cv2.imwrite(output_file, frame)

import os
from ultralytics import YOLO
import cv2

model = YOLO('runs/detect/train/weights/best.pt')

cap = cv2.VideoCapture(0)

cap.set(3, 1280)
cap.set(4, 720)

cv2.namedWindow('Live Object Detection', cv2.WINDOW_NORMAL)

threshold = 0.5

while True:
    ret, frame = cap.read()

    results = model(frame)

    for result in results.boxes.data.tolist():
        x1, y1, x2, y2, score, class_id = result

        if score > threshold:
            label = f'{results.names[int(class_id)].upper()}: {score:.2f}'
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)
            cv2.putText(frame, label, (int(x1), int(y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)

    cv2.imshow('Live Object Detection', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

import os
from ultralytics import YOLO
import cv2
from google.colab import files
from IPython.display import HTML, display
from IPython.display import clear_output

model = YOLO('runs/detect/train/weights/best.pt')

uploaded_files = files.upload()

video_file = 'video.mp4'

cap = cv2.VideoCapture(video_file)

fps = int(cap.get(cv2.CAP_PROP_FPS)

output_file = 'output_video.mp4'
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_file, fourcc, fps, (1920, 1080)

threshold = 0.5

while True:
    ret, frame = cap.read()

    if not ret:
        break

    results = model(frame)

    for result in results.boxes.data.tolist():
        x1, y1, x2, y2, score, class_id = result

        if score > threshold:
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)
            label = f'{results.names[int(class_id)].upper()}: {score:.2f}'
            cv2.putText(frame, label, (int(x1), int(y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)

    out.write(frame)

cap.release()
out.release()

video_path = f'/content/{output_file}'
HTML(f'<video width="800" height="600" controls><source src="{video_path}" type="video/mp4></video>'

video_path = f'/content/{output_file}'
HTML(f'<video width="800" height="600" controls><source src="{video_path}" type="video/mp4></video>'

out_link = f'<a href="{output_file}" download>Download Annotated Video</a>'
display(HTML(out_link))

display(HTML(f'<video controls autoplay src="{output_file}" width="800" height="600"></video>')

import cv2

image = cv2.imread('/content/itsdrive/MyDrive/Aurora/2D vectors/Screenshot from 2023-10-26 20-12-21 (copy).png')

height, width, _ = image.shape

print(f"Image width: {width} pixels")
print(f"Image height: {height} pixels")
